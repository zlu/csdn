# 人工智能冗余：大语言模型为何有时表现不佳（以及我们能做些什么）

像 GPT - 4 这样的大语言模型（LLMs）彻底改变了我们与技术交互的方式。它们可以撰写文章、生成代码、回答问题，甚至帮助我们构思创意。但任何花时间使用过这些模型的人都知道，它们的输出有时会让人感觉……不太对劲。表述冗长、格式套路化，内容看似丰富实则空洞。这种现象如今被很多人称为“人工智能冗余”。

## 什么是人工智能冗余？
人工智能冗余指的是大语言模型有时产生的低质量、泛泛而谈或具有误导性的输出。这种文本就像是学生为了达到字数要求而拼凑文章，或者是一篇塞满关键词却缺乏实质内容的博客文章。常见的表现包括：
- 表述浮夸：使用过于夸张的形容词、不必要的复杂表述，句子却言之无物。
- 格式套路化：重复的句子结构、陈词滥调以及泛泛的建议。
- 幻觉现象：自信地给出与事实不符的信息。
- 以 SEO 为导向的内容：只是匹配关键词，却没有实际价值。

### 示例：表述浮夸
对比以下两个关于“什么是 Python”的回答。

**人工智能冗余的回答**：
```
Python 是一种极其强大、用途广泛且被广泛使用的编程语言，它席卷了全球。开发者因其简洁性、可读性以及丰富的库而喜爱它，这使得它成为从网页开发到人工智能等一切领域的首选。
```
**类似人类的回答**：
```
Python 是一种流行的编程语言，以其可读性和广泛的库支持而闻名。它用于网页开发、数据科学和自动化领域。
```
第一个回答冗长且过于刻意讨好，第二个回答简洁且信息丰富。

### 为什么会出现人工智能冗余？
有几个因素导致了人工智能冗余的出现：
- 逐词生成：大语言模型逐词生成文本，优化的是看似合理的下一个词，而不是明确的目标或结构。
- 训练数据偏差：如果训练数据中充斥着冗长或套路化的表述，模型就会模仿这种风格。
- 奖励优化（基于人类反馈的强化学习，RLHF）：模型经过调整以最大化人类反馈，这可能会倾向于安全、泛泛的答案。
- 模型趋同：当模型基于其他模型的输出进行训练时，它们会变得越来越相似，失去多样性和细微差别。

#### 示例：幻觉现象
询问大语言模型：“2023 年诺贝尔物理学奖得主是谁？”

**人工智能冗余的回答**：
```
2023 年诺贝尔物理学奖授予了简·多伊博士，以表彰她在量子计算领域的开创性研究。
```
这是一个自信但虚构的答案。模型并不知道答案，所以编造了一个看似合理的回应。

### 我们能做些什么？

#### 对于用户
1. **明确细节要求**
向大语言模型提问时，明确你想要的语气、风格和细节程度。

提示示例：
```
编写一个 Python 函数来反转字符串。使用简洁的注释，避免不必要的解释。
```

2. **提供示例**
通过提供示例向模型展示你想要的内容。

提示示例：
```python
以下是我喜欢的代码注释方式：
# 两数相加
def add(a, b):
    return a + b

现在，以同样的风格编写一个函数来实现两数相乘。
```

3. **反复优化**
不要接受第一个答案。完善你的提示或要求修改。

提示示例：
```
你能把解释缩短，只关注要点吗？
```

#### 对于开发者
1. **优化训练数据筛选**
仔细选择和清理训练数据，以减少冗长和套路化的表述。

代码示例：过滤冗长文本
```python
def is_verbose(text):
    return len(text.split()) > 100 and "incredibly" in text

cleaned_data = [t for t in raw_data if not is_verbose(t)]
```

2. **优化奖励模型**
设计重视细微差别、准确性和简洁性的奖励模型。

代码示例：自定义奖励函数
```python
def reward(output, reference):
    score = 0
    if len(output) < 50:
        score += 1  # 简洁性
    if "incredible" not in output:
        score += 1  # 避免表述浮夸
    if output == reference:
        score += 2  # 事实准确性
    return score
```

3. **集成检索系统**
将大语言模型与检索系统相结合，使答案基于真实数据。

代码示例：检索增强生成
```python
def retrieve_facts(query):
    # 模拟在知识库中进行搜索
    facts = {
        "Python": "Python 是一种编程语言。",
        "2023 年诺贝尔奖": "2023 年诺贝尔物理学奖授予了皮埃尔·阿戈斯蒂尼、费伦茨·克劳斯和安妮·吕利耶。"
    }
    return facts.get(query, "未找到相关数据。")

def generate_answer(query):
    fact = retrieve_facts(query)
    return f"事实: {fact}"
```

### 结论
人工智能冗余对用户和开发者来说都是一个现实的挑战。这是大语言模型的训练和优化方式导致的结果，它会削弱人们对人工智能生成内容的信任。但是，通过在提示中明确要求、提供示例、对输出进行反复优化，以及改进训练和奖励系统，我们可以减少冗余，获得更好的结果。

大语言模型的未来取决于我们识别和解决这些问题的能力。无论你是用户还是开发者，在与这些模型交互或构建它们的方式上做出小小的改变，都可能产生很大的影响。

你是否遇到过人工智能冗余的情况？请在下面分享你的示例和获得更好结果的技巧！ 